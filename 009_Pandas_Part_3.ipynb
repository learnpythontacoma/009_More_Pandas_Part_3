{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='graphics/embarassment-of-pandas-760x506.jpg'>\n",
    "\n",
    "# Even More Pandas - Part 3\n",
    "\n",
    "\n",
    "\n",
    "## Warm-up Practice\n",
    "Each block of code below has instructions in it in order to help us warm up for today's lesson. We have covered each of these skills, so there is nothing that you will face for which you don't already know the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the code in this block to load our practice DataFrame\n",
    "\n",
    "\n",
    "oktoberfest_df = pd.read_csv('data/oktoberfestgesamt19852018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first five rows of data in order to check our work and become familiar\n",
    "# with the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in our DataFrame, the feature (column) titles are in German, which is fine for some, but we really want to change them to English. \n",
    "\n",
    "Below is the translation from German to English for each column.\n",
    "1. jahr: year\n",
    "1. dauer: duration\n",
    "1. besucher_gesamt: total visitors\n",
    "1. besucher_tag: total daily visitors\n",
    "1. bier_preis: beer price (in Euros)\n",
    "1. bier_konsum: beer consumed (in liters)\n",
    "1. hendl_preis: chicken price (in Euros)\n",
    "1. hendl_konsum: chickens consumed\n",
    "\n",
    "Using any technique you wish, change the feature names to English and make the 'year' column the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull up a sample of 8 rows to inspect our DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the columns and determine if they are the right type for the information\n",
    "# they hold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the min, max, mean and average of each integer/float column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you are satisfied with the results, run this code to save the cleaned table\n",
    "\n",
    "oktoberfest_df.to_csv('data/oktoberfest_english.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge, Join and Concatenate\n",
    "\n",
    "<img src='graphics/joins1.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our necessary pandas library\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "#Make three DataFrames for us to work with in the beginning of this notebook\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    " \n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                    index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                   index=[8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the next block of code to check out our work above. Take a few moments to get an idea of \n",
    "1. what each DataFrame contains\n",
    "1. how each DataFrame is constructed\n",
    "1. how each DataFrame is organized\n",
    "\n",
    "We will need to know this as we work further on this notebook's lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1)\n",
    "display(df2)\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Join\n",
    "\n",
    "The first stop in our journey of Merge, Join and Concatenate will be to do the simplest join - a Full Outer Join.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2, df3] \n",
    "\n",
    "df4 = pd.concat(frames)\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Join and Change of Keys\n",
    "\n",
    "To merge or concatenate a set of DataFrames, as we just did above, is incredibly helpful, but what happens when you want extract only a original portion of an pre-merged DataFrame from the new DataFrame? In that case, you can set keys on the data sets. \n",
    "\n",
    "In the next example, we concatenate `df1`, `df2` and `df3` as we just did above. Notice that we add the 'keys=' parameter to the concatenate command line. This will key each of the former DataFrames so that we might extract original data from the new DataFrame.\n",
    "\n",
    "Run the next block of code, then note how the keys `df1`, `df2` and `df3` are integrated into the new DataFrame (`df5`). As to the keys, you can use any variable or name that you want to use. I used the names of the former DataFrames in this example clarity reasons only. \n",
    "\n",
    "**REMEMBER that when you place single or double quotes around a character (numeric, alphabetic, or alpha-numeric) those characters become a string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2, df3]\n",
    "\n",
    "df5 = pd.concat(frames, keys=['df1', 'df2', 'df3'])\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you find that you want to know what of the new data was originally in `df2`. By using the `.loc` command that we learned in the last meet-up and calling the `df2` key, we extract information that was from `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.loc['df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways to handle axes when joining DataFrames\n",
    "\n",
    "When gluing together multiple DataFrames, you have a choice of how to handle the other axes (other than the one being concatenated). This can be done in the following two ways:\n",
    "\n",
    "- Take the union of them all, join='outer'. This is the default option as it results in zero information loss.\n",
    "- Take the intersection, join='inner'.\n",
    "\n",
    "\n",
    "Here is an example of each of these methods. First, the default join='outer' behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])\n",
    "\n",
    "result = pd.concat([df1, df4], axis=1, sort=False)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And second, here is the same thing with join='inner'. \n",
    "\n",
    "After you run the block, notice that it only provides the rows where the information of the two DataFrames overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=1, join='inner')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the parameters in the inner join command. First, the DataFrames you want to join are in square brackets and separated by a comma. Next, you specify the axis you want to join along. Axis 0 is rows and Axis 1 is columns. Finally, with the join parameter we tell Pandas what type of join we want. In this case, we want an inner join.\n",
    "\n",
    "## Reindexing joined DataFrames\n",
    "\n",
    "Lastly, suppose we just wanted to reuse the exact index from the original DataFrame (remember that an index specifies the row numbers that the DataFrame keys off of). The original DataFrame (`df1`) had the row indexes of 0, 1, 2, 3, 4.\n",
    "\n",
    "Looking at the concatenate command, we set the first parameter by naming the DataFrames we want to join in square brackets. Next, we set the axis parameter (in this case, we want to use the row index - axis=1). Then we use the `.reindex()` command and set its parameter to the index of `df1`. \n",
    "\n",
    "Run the next block to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=1).reindex(df1.index)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignoring indexes on the concatenation axis\n",
    "\n",
    "For DataFrame objects which donâ€™t have a meaningful index, you may wish to append them and ignore the fact that they may have overlapping indexes. To do this, use the `ignore_index` argument in the concatenation command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], ignore_index=True, sort=False)\n",
    "\n",
    "display('df1', df1)\n",
    "display('df4', df4)\n",
    "\n",
    "display('result', result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging two dataframes along a column name\n",
    "\n",
    "### Inner Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df1, df4, on='B', how='inner')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df1, df4, on='B', how='outer')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df1, df4, on='B', how='right')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df1, df4, on='B', how='left')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge while adding a suffix to duplicate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df1, df4, on='B', how='outer', suffixes=('_left', '_right'))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "\n",
    "We have covered a lot, so not it is time for you to pratice.\n",
    "\n",
    "## Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "df_a = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "df_b = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a third DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "df_n = pd.DataFrame(raw_data, columns = ['subject_id','test_id'])\n",
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join df_a and df_b along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join df_a and df_b along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge df_a and df_b with outer join along the `subject_id` value\n",
    "\n",
    "Add the appropriate suffixes so that we know where the merged data came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge df_a and df_b with inner join along `subject_id` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
